{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066423ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:06<00:00,  1.20it/s]\n",
      "100%|██████████| 80/80 [00:31<00:00,  2.53it/s]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import csv\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Target URL format with placeholder for pagination\n",
    "target_url = \"https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords={}&location={}&start={}\"\n",
    "\n",
    "\n",
    "def text_clean(text):\n",
    "    text = re.sub(r\"\\n\\n+\", \"\\n\\n\", text)\n",
    "    text = re.sub(r\"\\t+\", \"\\t\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# Define a user agent\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\",\n",
    "    \"Cache-Control\": \"max-age=0\",\n",
    "}\n",
    "\n",
    "# List to store job IDs\n",
    "job_ids = []\n",
    "job_data = []\n",
    "\n",
    "# Calculate number of pages to scrape (25 jobs per page)\n",
    "total_jobs = 200  # Example number\n",
    "pages = math.ceil(total_jobs / 25)\n",
    "\n",
    "# Get all job IDs\n",
    "for i in tqdm(range(0, pages)):\n",
    "    res = requests.get(\n",
    "        target_url.format(\"senior Data scientist\", \"remote\", i * 25), headers=headers\n",
    "    )\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "    jobs_on_page = soup.find_all(\"li\")\n",
    "\n",
    "    for job in jobs_on_page:\n",
    "        try:\n",
    "            job_id = (\n",
    "                job.find(\"div\", {\"class\": \"base-card\"})\n",
    "                .get(\"data-entity-urn\")\n",
    "                .split(\":\")[-1]\n",
    "            )\n",
    "            job_ids.append(job_id)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "# Get details for each job\n",
    "job_details_url = \"https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/{}\"\n",
    "for job_id in tqdm(job_ids):\n",
    "    resp = requests.get(job_details_url.format(job_id), headers=headers)\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "    job_info = {}\n",
    "    try:\n",
    "        job_info[\"company\"] = (\n",
    "            soup.find(\"div\", {\"class\": \"top-card-layout__card\"})\n",
    "            .find(\"a\")\n",
    "            .find(\"img\")\n",
    "            .get(\"alt\")\n",
    "        )\n",
    "        job_info[\"title\"] = (\n",
    "            soup.find(\"div\", {\"class\": \"top-card-layout__entity-info\"})\n",
    "            .find(\"a\")\n",
    "            .text.strip()\n",
    "        )\n",
    "        # job_info[\"level\"] = soup.find(\"ul\", {\"class\": \"description__job-criteria-list\"}).find(\"li\").text.replace(\"Seniority level\", \"\").strip()\n",
    "\n",
    "        # Get all li elements in the list\n",
    "        criteria_list = soup.find(\n",
    "            \"ul\", {\"class\": \"description__job-criteria-list\"}\n",
    "        ).find_all(\"li\")\n",
    "\n",
    "        # Field names in order they typically appear\n",
    "        field_names = [\"level\", \"employment_type\", \"job_function\", \"industries\"]\n",
    "        field_labels = [\n",
    "            \"Seniority level\",\n",
    "            \"Employment type\",\n",
    "            \"Job function\",\n",
    "            \"Industries\",\n",
    "        ]\n",
    "\n",
    "        criteria_list = soup.find(\n",
    "            \"ul\", {\"class\": \"description__job-criteria-list\"}\n",
    "        ).find_all(\"li\")\n",
    "\n",
    "        # Process each field\n",
    "        for i, field in enumerate(field_names):\n",
    "            if i < len(criteria_list):\n",
    "                job_info[field] = (\n",
    "                    criteria_list[i].text.replace(field_labels[i], \"\").strip()\n",
    "                )\n",
    "            else:\n",
    "                job_info[field] = \"\"\n",
    "        job_info[\"description\"] = text_clean(\n",
    "            soup.find(\n",
    "                \"div\", {\"class\": \"description__text description__text--rich\"}\n",
    "            ).text.strip()\n",
    "        )\n",
    "        job_data.append(job_info)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a4fae152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_dict(job_data)\n",
    "df.to_csv(\"linkedin_jobs.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "44cd9d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pprint\n",
    "# pprint.pprint(df.iloc[0,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1377dc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LINKEDIN_JOB_SEARCH_URL' from 'genu.Job_agent.config' (/home/alireza/projects/GenU/genu/Job_agent/config.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mschema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Document\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgenu\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mJob_agent\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LINKEDIN_JOB_SEARCH_URL, HEADERS\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgenu\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m text_clean\n\u001b[32m     15\u001b[39m persist_directory = \u001b[33m\"\u001b[39m\u001b[33m../data/job_data/vectorstore\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'LINKEDIN_JOB_SEARCH_URL' from 'genu.Job_agent.config' (/home/alireza/projects/GenU/genu/Job_agent/config.py)"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "from genu.Job_agent.config import LINKEDIN_JOB_SEARCH_URL, HEADERS\n",
    "from genu.utils import text_clean\n",
    "\n",
    "persist_directory = \"../data/job_data/vectorstore\"\n",
    "\n",
    "# # Later, to load the saved vector store:\n",
    "# loaded_vectorstore = Chroma(\n",
    "#     persist_directory=f\"{persist_directory}_chroma\",\n",
    "#     embedding_function=OpenAIEmbeddings(),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a220533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get all documents\n",
    "# all_docs = loaded_vectorstore.get()\n",
    "\n",
    "# # Access the documents\n",
    "# documents = all_docs[\"documents\"]  # List of document contents\n",
    "# metadatas = all_docs[\"metadatas\"]  # List of document metadata\n",
    "# ids = all_docs[\"ids\"]  # List of document IDs\n",
    "\n",
    "# # Print first few documents with their metadata\n",
    "# for i in range(min(5, len(documents))):\n",
    "#     print(f\"Document {i+1} (ID: {ids[i]}):\")\n",
    "#     print(f\"Content: {documents[i]}\")\n",
    "#     print(f\"Metadata: {metadatas[i]}\")\n",
    "#     print(\"-\" * 50)\n",
    "\n",
    "# # Get total count\n",
    "# print(f\"Total documents: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51bd415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get similar documents to a query\n",
    "# query = \"Optum\"\n",
    "# similar_docs = loaded_vectorstore.similarity_search(\n",
    "#     query, k=5\n",
    "# )  # k is number of results\n",
    "\n",
    "# # Print the retrieved documents\n",
    "# for i, doc in enumerate(similar_docs):\n",
    "#     print(f\"Result {i+1}:\")\n",
    "#     print(f\"Content: {doc.page_content}\")\n",
    "#     print(f\"Metadata: {doc.metadata}\")\n",
    "#     print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbc725d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS vectorstore count: 24\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "persist_directory = \"data/job_data/vectorstore\"\n",
    "loaded_vectorstore = FAISS.load_local(\n",
    "    f\"../{persist_directory}_faiss\",\n",
    "    OpenAIEmbeddings(),\n",
    "    allow_dangerous_deserialization=True,\n",
    ")\n",
    "# For FAISS\n",
    "\n",
    "print(\"FAISS vectorstore count:\", len(loaded_vectorstore.index_to_docstore_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b734d17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='1f6e9753-7e05-41cd-9784-dde4b259831d', metadata={'company': 'Harnham', 'title': 'Director, Data Science', 'level': 'Director', 'employment_type': 'Full-time', 'job_function': 'Analyst', 'industries': 'Financial Services', 'link': 'https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4233084632', 'date': '2025-05-26'}, page_content='Director, Data Science \\n Harnham \\n Director of Data ScienceIndustry Leader – Financial Services$195,000 - $225,000 base salary + BonusRemote – EST/CST preferred The Company:A fast-growing, mission-driven organization transforming the financial services space through advanced analytics and AI-powered solutions. With a strong focus on ethical data use and measurable impact, they’re building out a modern data organization to deliver scalable, production-grade ML across marketing, sales, CX, and operations.The Role – Director of Data Science:This is an ideal opportunity for a highly technical leader ready to take the next step into a Director-level role. You’ll lead a small but growing team in building and deploying predictive and prescriptive models, collaborating with MLOps and Data Engineering to deliver business-critical solutions.You’ll spend roughly half your time hands-on coding in Python/SQL, developing models, and solving business problems, and the other half managing, mentoring, and shaping the roadmap of the data science function.Responsibilities:Own the delivery of 10–12 production ML models annually across key functions (marketing, sales, ops, CX).Lead discovery, stakeholder engagement, solution design, model development, and deployment.Contribute 50%+ of your time to coding and technical delivery (Python, SQL).Manage and grow a high-performing team of Data Scientists, a Data PM, and collaborate with MLOps.Champion best practices in ML development, model monitoring, and responsible AI.Align data science initiatives with strategic business goals and communicate insights to leadership.Your Skills and Experience:6–12 years of data science experience, including 2+ years in a leadership or team lead capacity.Strong experience building and deploying models (regression, classification, clustering, forecasting).Deep proficiency in Python and SQL for model development and analytics.Comfortable partnering with stakeholders and aligning projects to business impact.Proven success in fast-paced, high-growth environments (not enterprise-only backgrounds).Experience working with MLOps teams, APIs, and production-level model delivery.Preferred Experience:Background in marketing, sales, or operations-focused data science.Experience in startups or scaling orgs (100–3,000 employees).Familiarity with tools like DataRobot, Snowflake, or similar ML platforms.Prior exposure to ML pipelines, model governance, and AI ethics.Strong leadership instincts with a desire to grow into a larger org-wide role over time.Benefits – Director of Data Science:This fully remote position offers a competitive base salary of $195,000–$225,000 (targeting $200–215K), a bonus, along with the opportunity to drive impact at an organization deeply committed to innovation and responsible AI.How to Apply:If you’re a hands-on data leader ready to scale a high-impact ML function, please submit your resume to express interest in this role.Keywords: Director of Data Science, Python, SQL, ML, AI, Marketing Analytics, Sales Analytics, Predictive Modeling, Leadership, Data Strategy, Remote Data JobsSeniority Level: DirectorIndustry: Financial Services, Technology, Data ScienceEmployment Type: Full-TimeJob Functions: Data Science, Machine Learning, Leadership, Product Strategy Show more Show less \\n Analyst \\n Financial Services'),\n",
       " Document(id='566f8730-3841-45e9-a831-68d7c7193385', metadata={'company': 'H-E-B', 'title': 'Data Scientist - eCommerce', 'level': 'Entry level', 'employment_type': 'Full-time', 'job_function': 'Engineering and Information Technology', 'industries': 'Hospitals and Health Care, Non-profit Organizations, and Government Administration', 'link': 'https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4216489085', 'date': '2025-05-26'}, page_content=\"Data Scientist - eCommerce \\n H-E-B \\n ResponsibilitiesH-E-B's Corporate Planning and Analysis Team develops and maintains budgets and financial systems while providing current, reliable financial data, analysis, and technical information.As a Data Scientist II, your archetype is an ML / AI Business Solution Designer. Your passions include creating end-to-end business solutions packages by integrating multi-modals and data pipelines, innovating new ML algorithms to establish strong competitive advantage for H-E-B business, and designing and implementing different ML integration patterns to facilitate multi-modal orchestration.Once you're eligible, you'll become an Owner in the company, so we're looking for commitment, hard work, and focus on quality and Customer service. 'Partner-owned' means our most important resources--People--drive the innovation, growth, and success that make H-E-B The Greatest Omnichannel Retailing Company.Do you have a:HEART FOR PEOPLE... willingness to take a break from algorithmic thinking / detecting to translate and share your findings with a variety of business customers?HEAD FOR BUSINESS... skills to blend mass data-wrangling with business acumen?PASSION FOR RESULTS... drive to generate business-valued questions and data-based n solutions?We are looking for: a thought leader of ML innovation who orchestrates business solutions across ML pipelinesWhat is the work?Analytics / Design & Development: Analyzes clickstream data and customer interactions to drive insights. Develops and deploy machine learning models to support e-commerce initiatives Presents findings to both technical and non-technical audiences, including senior leadership Manages multiple data science projects while collaborating with Product, Business, and Engineering teams Serves H-E-B as a thought leader in selected mainstream ML / AI fields Builds a concrete roadmap for ML solution maturity revolution Creates end-to-end business solutions packages by integrating multi-modals and data pipelines Designs / implements different ML integration patterns to facilitate multi-modal orchestration Innovates new ML algorithms to establish strong competitive advantage for H-E-B business; ensures new algorithms are backed by solid math and science proof Applies an inquisitive nature about open source algorithms, their theories, and their implementation Grows expertise in constructing distributed machine learning pipeline from scratchWhat is your background? A related degree or comparable formal training, certification, or work experience 5+ years of experience in a retail or retail-related decision science role Expertise / in-depth knowledge of business domain Well-rounded experience integrating math / science and platform engineeringDo you have what it takes to be a Data Scientist at H-E-B? Experience with Clickstream Analytics (BQ/Amplitude) (Preferably in Retail) Experience with Recommendation Systems Able to continuously learn new methodologies and applications of ML/AI techniques Strong capabilities in translating data science findings into business-friendly results. Able to present findings to leaders and peers. Ability to contribute to multiple work streams concurrently while staying connected to Product, Business, and Engineering teams. Experience working with visualization tools such as Tableau and Dash Proficiency in DS techniques (classification, regression, optimization) Some familiarity with big data ecosystems (e.g., Spark, Hadoop) and UNIX commands / scripting Understanding of best-in-class AI techniques to customize algorithms that created H-E-B-unique differentiators Strong research and analytical skills Critical and lateral thinking skills Experience working with e-commerce data and understanding customer behavior Proficiency in tools like BigQuery, Amplitude, or similar for clickstream data analysis Experience with Tableau, Dash, or equivalent platforms to visualize data Ability to develop end-to-end ML solutions, including NLU/LLM modeling Proficiency in Python, SQL, Spark Strong ability to present findings clearly and collaborate across teams Programming language skills (SQL, R, Python, Scala, Java, C/C++) ML optimization skills (GPU code optimization, Horovod, SparkMLlib optimization, Cython, JNI, Numba Mainstream ML / AI skills (deep learning, computer vision, NLP / NLU, reinforcement learning, meta-learning, federated learning) Ability to grow expertise in constructing distributed machine learning pipeline from scratchCan you... Work in a fast-paced retail environment with frequently shifting priorities Work extended hours; sit for long periods08-2021CPFA3232 Show more Show less \\n Engineering and Information Technology \\n Hospitals and Health Care, Non-profit Organizations, and Government Administration\")]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_vectorstore.similarity_search(\"price optimization\", k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63697dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Senior Data Analyst- Merchandising \\n'\n",
      " ' Quince \\n'\n",
      " ' OUR STORY Quince was started to challenge the existing idea that nice '\n",
      " 'things should cost a lot. Our mission was simple: create an item of equal or '\n",
      " 'greater quality than the leading luxury brands and sell them at a much lower '\n",
      " 'price.OUR VALUES Customer First. Customer satisfaction is our highest '\n",
      " 'priority.High Quality. True quality is a combination of premium materials '\n",
      " 'and high production standards that everyone can feel good about.Essential '\n",
      " \"design. We don't chase trends, and we don't sell everything. We're expert \"\n",
      " 'curators that find the very best and bring it to you at the lowest '\n",
      " 'prices.Always a better deal. Through innovation and real price transparency '\n",
      " 'we want to offer the best deal to both our customers and our factory '\n",
      " \"partners.Environmentally and Socially conscious. We're committed to \"\n",
      " 'sustainable materials and sustainable production methods. That means a '\n",
      " 'cleaner environment and fair wages for factory workers.OUR TEAM AND SUCCESS '\n",
      " 'Quince is a retail and technology company co-founded by a team that has '\n",
      " 'extensive experience in retail, technology and building early stage '\n",
      " \"companies. You'll work with a team of world-class talent from Stanford GSB, \"\n",
      " 'Google, D.E. Shaw, Stitch Fix, Urban Outfitters, Wayfair, McKinsey, Nike '\n",
      " 'etc.THE IDEAL CANDIDATEThe ideal candidate is a self-starter and '\n",
      " 'problem-solver, skilled at leveraging technology and data to deliver '\n",
      " 'top-tier analytics solutions. They thrive on addressing complex business '\n",
      " 'challenges and are consistently effective in making high-judgment decisions '\n",
      " 'at a rapid pace, even in the face of ambiguity and uncharted scenarios. '\n",
      " 'Additionally, the ideal candidate is energized by a work environment where '\n",
      " 'strategy, innovation, and decision-making are intentionally distributed, '\n",
      " 'where transparency, agility, and data-driven insights are highly valued, and '\n",
      " 'where colleagues at all levels hold each other to exceptionally high '\n",
      " 'standards to serve Quince customersRESPONSIBILITIES:Pricing Analysis & '\n",
      " 'Strategy:Analyze historical sales data, market trends, competitor pricing, '\n",
      " 'and customer behavior to develop data-backed pricing recommendations.Build '\n",
      " 'and maintain pricing models to evaluate the impact of different pricing '\n",
      " 'scenarios and strategies.Monitor pricing performance, identify anomalies, '\n",
      " 'and provide actionable insights to optimize pricing decisions.Collaborate '\n",
      " 'with Category Managers to understand product costs, margin targets, and '\n",
      " 'market dynamics to inform pricing strategies.Promotion Analysis & '\n",
      " 'Optimization:Evaluate the performance of past and ongoing promotional '\n",
      " 'campaigns, including discounts, bundles, and seasonal offers.Identify '\n",
      " 'opportunities to improve promotional effectiveness, target specific customer '\n",
      " 'segments, and optimize promotional timing.Conduct A/B testing on promotional '\n",
      " 'strategies and analyze the results to inform future campaigns.Reporting & '\n",
      " 'Visualization:Develop metrics and dashboards to track key promotional KPIs '\n",
      " '(e.g., conversion rates, average order value, incremental sales).Visualize '\n",
      " 'data effectively using tools like Looker, Google Data Studio to facilitate '\n",
      " 'understanding and decision-making.Present analytical findings and '\n",
      " 'recommendations to Merchandising, Marketing, and leadership teams.Data '\n",
      " 'Management & Integrity:Ensure the accuracy and integrity of data used for '\n",
      " 'analysis.Collaborate with data engineering teams to improve data collection, '\n",
      " 'storage, and accessibility.Develop and document data analysis processes and '\n",
      " \"methodologies.QUALIFICATIONS:Bachelor's degree in math, science, \"\n",
      " 'engineering, or related field.4-7 years of experience in data analytics, '\n",
      " 'preferably in an ecommerce setting.Strong analytical and problem-solving '\n",
      " 'skills.Excellent communication and interpersonal skills.Strong expertise in '\n",
      " 'SQL and BI tools for analyzing large datasets, with experience in developing '\n",
      " 'and maintaining dashboards to track business metrics.Experience with Agile '\n",
      " \"methodologies preferred.Bachelor's degree in finance, accounting, economics, \"\n",
      " 'mathematics, statistics, or a related field is typically required. We rely '\n",
      " 'on market indicators and consider your specific job family, background, '\n",
      " 'skills, and experience to determine your compensation in the market range. '\n",
      " \"Bonus eligibility varies by role and is determined based on the position's \"\n",
      " 'impact and contribution to our strategic goals.Pay Range$150,000—$200,000 '\n",
      " 'USDQuince provides equal employment opportunities to all employees and '\n",
      " 'applications for employment and prohibits discrimination and harassment of '\n",
      " 'any type without regard to race, color, religion, age, sex, national origin, '\n",
      " 'disability status, genetics, protected veteran or military status, sexual '\n",
      " 'orientation, gender identity or expression, or any other characteristic '\n",
      " 'protected by federal, state, or local laws.Security Advisory: Beware of '\n",
      " \"FraudsAt Quince, we're dedicated to recruiting top talent who share our \"\n",
      " 'drive for innovation. To safeguard candidates, Quince emphasizes legitimate '\n",
      " 'recruitment practices. Initial communication is primarily via official '\n",
      " 'Quince email addresses and LinkedIn; beware of deviations. Personal data and '\n",
      " 'sensitive information will not be solicited during the application phase. '\n",
      " 'Interviews are conducted via phone, in person, or through the approved '\n",
      " 'platforms Google Meets or Zoom—never via messaging apps or other calling '\n",
      " 'services. Offers are merit-based, communicated verbally, and followed up in '\n",
      " 'writing. If personal information is requested to initiate the hiring '\n",
      " 'process, rest assured it will be through secure and protected means. Show '\n",
      " 'more Show less \\n'\n",
      " ' Information Technology \\n'\n",
      " ' Technology, Information and Internet')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(loaded_vectorstore.similarity_search(\"price optimization\", k=5)[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6262f9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:16<00:00,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Target URL format with placeholder for pagination\n",
    "# target_url = \"https://www.linkedin.com/jobs/search/?currentJobId=4216706661&f_TPR=r604800&f_WT=2&geoId=103644278&keywords=senior%20data%20scientist&origin=JOB_SEARCH_PAGE_JOB_FILTER&refresh=true\"\n",
    "target_url = \"https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords={}&location={}&start={}\"\n",
    "# List to store job IDs\n",
    "job_ids = []\n",
    "job_data = []\n",
    "\n",
    "# Calculate number of pages to scrape (25 jobs per page)\n",
    "total_jobs = 500  # Example number\n",
    "pages = math.ceil(total_jobs / 25)\n",
    "\n",
    "# Get all job IDs\n",
    "for i in tqdm(range(0, pages)):\n",
    "    res = requests.get(target_url.format(\"Senior data scientist\", \"remote\", i * 25))\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "    jobs_on_page = soup.find_all(\"li\")\n",
    "\n",
    "    for job in jobs_on_page:\n",
    "        try:\n",
    "            job_id = int(\n",
    "                job.find(\"div\", {\"class\": \"base-card\"})\n",
    "                .get(\"data-entity-urn\")\n",
    "                .split(\":\")[-1]\n",
    "            )\n",
    "            # print(f\"Found job ID: {job_id}\")\n",
    "            job_ids.append(job_id)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing job: {e}\")\n",
    "            continue\n",
    "\n",
    "print(len(set(job_ids)))\n",
    "print(len(list(job_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4982b582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.linkedin.com/jobs/search/?currentJobId=4216706661&f_TPR=r604800&f_WT=2&geoId=103644278&keywords=senior%20data%20scientist&origin=JOB_SEARCH_PAGE_JOB_FILTER&refresh=true'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_url.format(\"Python\", \"New York\", i * 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a444fc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=senior%20data%20scientist&location=San%20Antonio&f_TPR=r604800\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=senior%20data%20scientist&location=united%20states&f_TPR=r604800&f_WT=2\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=senior%20data%20scientist&location=united%20states&f_TPR=r604800&f_JT=P&f_WT=2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=senior%20data%20scientist&location=San%20Antonio&f_TPR=r604800&start={}',\n",
       " 'https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=senior%20data%20scientist&location=united%20states&f_TPR=r604800&f_WT=2&start={}',\n",
       " 'https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=senior%20data%20scientist&location=united%20states&f_TPR=r604800&f_JT=P&f_WT=2&start={}']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from genu.Job_agent.config import HEADERS, LINKEDIN_JOB_SEARCH_PARAMS\n",
    "\n",
    "\n",
    "def linkedin_link_constructor(search_params: list[dict[str, str]]):\n",
    "\n",
    "    target_url = \"https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords={}&location={}&f_TPR={}\"\n",
    "\n",
    "    url_list = []\n",
    "    for params in search_params:\n",
    "        url = target_url.format(\n",
    "            params[\"keywords\"].replace(\" \", \"%20\"),\n",
    "            params[\"location\"].replace(\" \", \"%20\"),\n",
    "            params[\"f_TPR\"],\n",
    "            # params[\"start\"]\n",
    "        )\n",
    "        if params[\"parttime\"]:\n",
    "            url += \"&f_JT=P\"\n",
    "        if params[\"remote\"]:\n",
    "            url += \"&f_WT=2\"\n",
    "        print(url)\n",
    "        url_list.append(url + \"&start={}\")\n",
    "    return url_list\n",
    "    \n",
    "linkedin_link_constructor(LINKEDIN_JOB_SEARCH_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88805b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-05-26'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "datetime.datetime.now().date().isoformat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genu-dGEUhqWF-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
