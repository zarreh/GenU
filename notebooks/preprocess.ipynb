{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "# def find_recurring_phrases(text, min_length=20, threshold=2):\n",
    "#     \"\"\"\n",
    "#     Identifies recurring phrases in the text based on frequency.\n",
    "\n",
    "#     :param text: str, the input text.\n",
    "#     :param min_length: int, minimum character length of a phrase to consider.\n",
    "#     :param threshold: int, minimum occurrences to qualify as recurring.\n",
    "#     :return: list of str, recurring phrases.\n",
    "#     \"\"\"\n",
    "#     # Split into potential phrases (e.g., sentences or lines)\n",
    "#     phrases = re.split(r'[.\\n]', text)\n",
    "#     phrases = [phrase.strip() for phrase in phrases if len(phrase.strip()) >= min_length]\n",
    "\n",
    "#     # Count frequencies\n",
    "#     phrase_counts = Counter(phrases)\n",
    "#     recurring_phrases = [phrase for phrase, count in phrase_counts.items() if count >= threshold]\n",
    "\n",
    "#     return recurring_phrases\n",
    "\n",
    "# def remove_recurring_phrases_dynamically(text, min_length=20, threshold=2):\n",
    "#     \"\"\"\n",
    "#     Finds and removes recurring phrases from the text dynamically.\n",
    "\n",
    "#     :param text: str, the input text to clean.\n",
    "#     :param min_length: int, minimum character length of a phrase to consider.\n",
    "#     :param threshold: int, minimum occurrences to qualify as recurring.\n",
    "#     :return: str, cleaned text.\n",
    "#     \"\"\"\n",
    "#     # Identify recurring phrases\n",
    "#     recurring_phrases = find_recurring_phrases(text, min_length, threshold)\n",
    "    \n",
    "#     # Remove recurring phrases\n",
    "#     for phrase in recurring_phrases:\n",
    "#         escaped_phrase = re.escape(phrase)  # Escape for regex\n",
    "#         text = re.sub(escaped_phrase, '', text)\n",
    "\n",
    "#     # Clean up extra spaces and newlines\n",
    "#     text = re.sub(r'\\s{2,}', ' ', text)\n",
    "#     text = re.sub(r'\\n{2,}', '\\n', text)\n",
    "    \n",
    "#     return text, recurring_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to open: ../data/crawled_content/klesse_utsa_edu.txt\n"
     ]
    }
   ],
   "source": [
    "BASE_PATH = \"../data/crawled_content\"\n",
    "UNIVERSITY_STR = [\"uiw_edu\", \"stmary_edu\", \"klesse_utsa_edu\"][-1]\n",
    "full_path = f\"{BASE_PATH}/{UNIVERSITY_STR}.txt\"\n",
    "\n",
    "print(f\"Attempting to open: {full_path}\")\n",
    "\n",
    "with open(full_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "    content = file.read()    \n",
    "    # print(content)\n",
    "\n",
    "content = content.replace(\"|\", \"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 422 matches.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def robust_chunk_text_with_warning(text, max_chunk_size=2000):\n",
    "    \"\"\"\n",
    "    Splits text into chunks, ensuring sections defined by LINK, TITLE, and CONTENT\n",
    "    remain intact and are not split between chunks. Raises a message if any page exceeds max_chunk_size.\n",
    "    \n",
    "    :param text: str, the input text to split into chunks.\n",
    "    :param max_chunk_size: int, the maximum size of each chunk.\n",
    "    :return: list of str, the text chunks.\n",
    "    \"\"\"\n",
    "    def preprocess_text(text):\n",
    "        \"\"\"Normalizes spacing and line breaks.\"\"\"\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        text = re.sub(r'\\n+', '\\n', text)\n",
    "        return text\n",
    "\n",
    "    # Preprocess text to normalize formatting\n",
    "    text = preprocess_text(text)\n",
    "    \n",
    "    # Enhanced regex to allow for flexible spacing and line breaks\n",
    "    pattern = r'(LINK: .*?TITLE: .*?CONTENT: .*?)(?=LINK:|$)'\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    \n",
    "    if not matches:\n",
    "        print(\"No matches found. Check formatting or regex.\")\n",
    "        return []\n",
    "    else:\n",
    "        print(f\"Found {len(matches)} matches.\")\n",
    "    \n",
    "    # Check if any single page exceeds max_chunk_size\n",
    "    for i, section in enumerate(matches):\n",
    "        if len(section) > max_chunk_size:\n",
    "            print(f\"Warning: Page {i+1} exceeds max_chunk_size ({len(section)} characters). Please review:\")\n",
    "            print(section[:500] + \"...\\n\")  # Show the first 500 characters for context\n",
    "    \n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_size = 0\n",
    "\n",
    "    for section in matches:\n",
    "        section_size = len(section)\n",
    "        \n",
    "        # Check if adding this section exceeds the max chunk size\n",
    "        if current_size + section_size > max_chunk_size and current_chunk:\n",
    "            # Finalize the current chunk\n",
    "            chunks.append(''.join(current_chunk).strip())\n",
    "            current_chunk = []\n",
    "            current_size = 0\n",
    "\n",
    "        # Add the section to the current chunk\n",
    "        current_chunk.append(section)\n",
    "        current_size += section_size\n",
    "\n",
    "    # Add the last chunk\n",
    "    if current_chunk:\n",
    "        chunks.append(''.join(current_chunk).strip())\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Chunk the text\n",
    "chunks = robust_chunk_text_with_warning(content, max_chunk_size=500000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401457"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
